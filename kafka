1 mysql 为什么使用B+ TREE 而不使用B-Tree 或者红黑树
红黑树：其特点是保证了左子树和右子树的高度差不会超过1，但是本身其有两个问题：1 是无法解决范围查询的问题，2是当数据数量比较大的时候，查询结果仍然是一个比较耗时的过程。
b-tree结构特点 ： b-tree 叫做多路平衡查找树，其在AVL树的基础上做了优化，主要针对当数据量非常大的时候，通过增加每个节点存储的值，来降低树的高度，
每个节点存储两个值，其结构特点是所有的节点都存储相应的data域，这样无疑增加了节点大小，说白了就是增加了磁盘I/O的次数，操作系统读取数据是按照page页
来进行读取的，一般是4K大小。并且针对范围查询，B-TREE会存在多次回查，存在效率不高的情况。
B+TREE： 通过树结构 + 底层线性列表的方式，通过二叉树结构对索引快速定位，针对范围查询则通过底层链表结构，底层链表按照顺序连接了所有叶子节点的数据，
可以有效的快速定位范围查询结果。
2 MQ消息丢失、消息堆积、重复消费问题？
MQ消息丢失：分析消息丢失在哪个阶段出现,
			1 当生产端到broker是否出现消息丢失
			① 假如当生产端生产消息推送到服务端时，出现网络波动或者rebalance情况下，导致消息推送失败
			此时解决方案有：设置ack = 1 保证数据写入leader后返回成功标志，并设置retries > 0 表示进行失败重试，并设置合理的retry.backoff.ms= 100 设置重试时间。
			② 当因为max.request.size 导致的消息丢失是无法恢复的
			因此解决方法：通过将错误消息入DB或redis中，防止消息数据超过request.size导致消息丢失。
			
			2 broker到消费端出现消息丢失
			配置方式：
			group.id= consumer group 分组的一个id
			消费者隶属的消费组名称，在kafka中，消息只能被某个组里面的一个consumer端消费。
			auto.offset.reset = earliest(最早) /latest(最晚)
			从何处开始进行消费，　　当一个新加入的consumer要进行消费数据，如果这个consumer是做数据分析工作的，
			是需要以前的历史数据那就需要从最早的位置消费数据，如果仅仅是查看消费情况，那可以从最晚位置开始消费数据。
			enable.auto.commit = true/false(默认true)
			如果设置为Ture则表示由客户端自己维护offset的提交工作，会隔一段时间自行提交offset给broker上。如果为false则需要自己在代码中维护。
			auto.commit.interval.ms  
			当enable.auto.commit设置为true时才生效，表示开启自动提交消费位移功能时自动提交消费位移的时间间隔。
			解决思路（分析产生消息丢失的原因）：
			在consumer消费阶段，对offset的处理，关系到是否丢失数据，是否重复消费数据，因此，我们把处理好offset就可以做到exactly-once && at-least-once(只消费一次)数据。
			当enable.auto.commit=true时
	　　　　表示由kafka的consumer端自动提交offset,当你在pull(拉取)30条数据，在处理到第20条时自动提交了offset,但是在处理21条的时候出现了异常，当你再次pull数据时，
			由于之前是自动提交的offset，所以是从30条之后开始拉取数据，这也就意味着21-30条的数据发生了丢失。当enable.auto.commit=false时
	　　　　由于上面的情况可知自动提交offset时，如果处理数据失败就会发生数据丢失的情况。那我们设置成手动提交。
	　　　　当设置成false时，由于是手动提交的，可以处理一条提交一条，也可以处理一批，提交一批，由于consumer在消费数据时是按一个batch来的，当pull了30条数据时，
			如果我们处理一条，提交一个offset，这样会严重影响消费的能力，那就需要我们来按一批来处理，或者设置一个累加器，处理一条加1，如果在处理数据时发生了异常，
			那就把当前处理失败的offset进行提交(放在finally代码块中)注意一定要确保offset的正确性，当下次再次消费的时候就可以从提交的offset处进行再次消费。
			
			解决方案：1 对于消息不丢失而言，我们需要的语义是精确一次的操作，因此我们对于消息丢失会进行分析，为了避免客户端auto.commit 引起的消息丢失，会设置auto.commit
			=false 则在代码中手动提交offset ，因为考虑吞吐量的问题，我们不会一个消息提交一次offset,一般是一次提交批量的offset，因此在程序中需要手动计数，当消费完一定
			数据后则手动提交。
			2 如果在处理过程中发生错误的情况，可以将错误消息存储起来，进行后面补偿机制下的错误重试，不应该影响后续的消息消费。
			3 如果单个消息处理事件过长，可以采用异步多线程的方式处理消息，利用线程池提高消息的消费效率，因为线程池的处理行为是并行的，所以要对offset进行判断，如果当前
			消息消费的offset存储起来，假如此时又提交了1个offset,把2个offset相对比，哪个大把哪个存起来并做提交。如果消息处理发生了错误，
			我们在前面讲过，把这个错误消息发送到专门处理错误的topic中，让专门的consumer来处理。	
MQ消息堆积：分析堆积是怎么产生的
			1 生产端因为QPS突然增大导致：
			2 因为消费端出现消费瓶颈，分析瓶颈出现的原因
MQ重复消费问题：分析重复消费的影响
			1 如果消费者消费消息是幂等性操作，则不需要管。
			2 如果不是则分析
			  生产者生产重复消息？
			  从broker上发送重复消息到对应的消费者？
			对于重复消费问题，通用的做法可以通过数据库表+sequenceId来唯一确定。
			对于不用中间件而言，可以以kafka为例：
			kafka本身是通过topic订阅的方式来消费消息，同一个group组之间消息只能消费一次
			而kakfa本身通过offset记录消息消费的位置，我们可以在消费者中设置auto_commit = false
			来设置手动commit offset，当我们消费消息完毕时，通过客户端手动提交offset的方式，来确定
			消息消费完毕。
			
			
kafka

消息丢失

1 producer端产生原因

网路波动或者产生rebanlance

消息数量超过了request.max.size

解决办法

1 高可用型

配置：acks = all，retries > 0 retry.backoff.ms=100(毫秒) (并根据实际情况设置retry可能恢复的间隔时间)

　　优点：这样保证了producer端每发送一条消息都要成功，如果不成功并将消息缓存起来，等异常恢复后再次发送。

　　缺点：这样保证了高可用，但是这会导致集群的吞吐量不是很高，因为数据发送到broker之后，leader要将数据同步到fllower上，如果网络带宽、不稳定等情况时，ack响应时间会更长

2 折中型

　　配置：acks = 1  retries > 0 retries 时间间隔设置 (并根据实际情况设置retries可能恢复的间隔时间)

　　优点：保证了消息的可靠性和吞吐量，是个折中的方案

　　缺点：性能处于2者中间

3 高吞吐型

　　配置：acks = 0

　　优点：可以相对容忍一些数据的丢失，吞吐量大，可以接收大量请求

　　缺点：不知道发送的消息是 否成功

2 消费端产生原因

1 未设置手动offset操作，客户端自己隔一段时间去维护offset值，导致消息消费失败，而offset已更新。

2 消费端消费失败后提交offset未设置对应补偿机制导致

解决办法

auto.commit 设置为false，手动维护offset值，当消费成功则提交offset值，消费失败投递到对应失败队列，开启相应补偿机制。

消息消费部分场景

1.一直commit offset的处理

　　　　假如poll了100条数据，每处理1条，commit offset一次，这样会严重影响性能，在处理的时候设置1个计数器(或累加器)，按一批来提交，但要确保提交offset的准确性

　　2.rebalance的影响

　　　　在处理数据时，有2种情况会发生，一种情况是处理了一半的时候，发生了rebalance，但是offset还没有来得及提交，另一种情况是rebalance发生后，重新分配了offset,在这种情况时会发生错误。

　　3.消息处理错误时的处理

　　　　　假如consumer在处理数据的时候失败了，那么可以把这条数据给缓存起来，可以是redis、DB、file等，也可以把这条消息存入专门用于存储失败消息的topic中，让其它的consumer专门处理失败的消息。

　　4.处理消息的时间过长

　　　　假如poll一批100条消息的时间是1秒钟，但是在每处理1条需要花费1秒钟，这样来说极其影响消费能力，那我们可以把100条消息放到1个线程池中处理。这里特别特别注意，由于线程池的处理行为是并行的，所以要做对offset的判断。这里先说正常情况，如果消息都能被正常处理，那么会提交1个offset，并把这个offset存起来，假如此时又提交了1个offset,把2个offset相对比，哪个大把哪个存起来并做提交。如果消息处理发生了错误，我们在前面讲过，把这个错误消息发送到专门处理错误的topic中，让专门的consumer来处理。

消息重复消费

1 producer端产生原因

处理消息时间过长，被broker移除后，消息被重新分配

产生rebanlance操作引起

解决方法

kafka 0.11.0以上版本已支持对exactly once 的支持，因为在producer端是批量发送消息，因此需要进行幂等性验证，每次发送端带一个sequenceId，接收端进行校验，重复的丢弃。

2 consumer产生原因

接收端出现的原因是消息消费成功，而offset未提交导致的重复消费

解决办法

将消息的消费和offset的提交放到一个事务下，保证消费消费和offset要么都成功，要么都失败。

消息堆积

1 生产端，业务峰值产生大量的消息

解决办法:增加消费者数量

2 消费端，消费时间过长导致被剔除消费组

设置合理的消费时长，和即max.poll.interval.ms 和 max.poll.records,因为当消费时间过长时，服务端会认为当前消费者挂掉，因此将其踢出消费组，因此导致消息堆积。

			
